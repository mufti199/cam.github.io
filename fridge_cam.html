<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Object Recognition Camera</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/tensorflow/4.10.0/tf.min.js"></script>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
            backdrop-filter: blur(10px);
            max-width: 600px;
            width: 100%;
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 30px;
            font-size: 2.5em;
            font-weight: 700;
        }

        .camera-container {
            position: relative;
            margin-bottom: 30px;
            border-radius: 15px;
            overflow: hidden;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        #video {
            width: 100%;
            height: 400px;
            object-fit: cover;
            display: block;
        }

        #canvas {
            display: none;
        }

        .controls {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-bottom: 30px;
        }

        button {
            padding: 12px 24px;
            border: none;
            border-radius: 25px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            min-width: 120px;
        }

        .primary-btn {
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
        }

        .primary-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4);
        }

        .primary-btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }

        .results {
            background: rgba(255, 255, 255, 0.8);
            border-radius: 15px;
            padding: 20px;
            margin-top: 20px;
            min-height: 100px;
        }

        .result-item {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 10px 0;
            border-bottom: 1px solid rgba(0, 0, 0, 0.1);
        }

        .result-item:last-child {
            border-bottom: none;
        }

        .object-name {
            font-weight: 600;
            color: #333;
            text-transform: capitalize;
        }

        .confidence {
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            padding: 4px 12px;
            border-radius: 20px;
            font-size: 14px;
            font-weight: 600;
        }

        .status {
            text-align: center;
            margin: 20px 0;
            font-size: 18px;
            color: #666;
        }

        .loading {
            color: #667eea;
            font-weight: 600;
        }

        .error {
            color: #e74c3c;
            font-weight: 600;
        }

        .success {
            color: #27ae60;
            font-weight: 600;
        }

        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }

            h1 {
                font-size: 2em;
            }

            #video {
                height: 300px;
            }

            .controls {
                flex-direction: column;
                align-items: center;
            }

            button {
                width: 100%;
                max-width: 250px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸŽ¯ Object Recognition</h1>
        
        <div class="camera-container">
            <video id="video" autoplay playsinline></video>
            <canvas id="canvas"></canvas>
        </div>

        <div class="controls">
            <button id="startBtn" class="primary-btn">Start Camera</button>
            <button id="captureBtn" class="primary-btn" disabled>Analyze Image</button>
        </div>

        <div class="status" id="status">Click "Start Camera" to begin</div>

        <div class="results" id="results" style="display: none;">
            <h3 style="margin-bottom: 15px; color: #333;">Detection Results:</h3>
            <div id="predictions"></div>
        </div>
    </div>

    <script>
        let video, canvas, ctx, model;
        let isModelLoaded = false;

        const statusEl = document.getElementById('status');
        const startBtn = document.getElementById('startBtn');
        const captureBtn = document.getElementById('captureBtn');
        const resultsEl = document.getElementById('results');
        const predictionsEl = document.getElementById('predictions');

        // Initialize the app
        async function init() {
            video = document.getElementById('video');
            canvas = document.getElementById('canvas');
            ctx = canvas.getContext('2d');

            // Load the model
            await loadModel();

            // Set up event listeners
            startBtn.addEventListener('click', startCamera);
            captureBtn.addEventListener('click', captureAndAnalyze);
        }

        async function loadModel() {
            try {
                statusEl.textContent = 'Loading AI model...';
                statusEl.className = 'status loading';
                
                // Load MobileNet model for object recognition
                model = await tf.loadLayersModel('https://storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_0.25_224/model.json');
                
                // Load ImageNet class names
                const response = await fetch('https://storage.googleapis.com/tfjs-models/tfjs/mobilenet_v1_0.25_224/imagenet_classes.json');
                window.imagenetClasses = await response.json();
                
                isModelLoaded = true;
                statusEl.textContent = 'Model loaded successfully! Ready to recognize objects.';
                statusEl.className = 'status success';
            } catch (error) {
                console.error('Error loading model:', error);
                statusEl.textContent = 'Error loading model. Please refresh the page.';
                statusEl.className = 'status error';
            }
        }

        async function startCamera() {
            try {
                statusEl.textContent = 'Requesting camera access...';
                statusEl.className = 'status loading';

                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { 
                        facingMode: 'environment',
                        width: { ideal: 640 },
                        height: { ideal: 480 }
                    }
                });

                video.srcObject = stream;
                
                video.onloadedmetadata = () => {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    
                    startBtn.textContent = 'Camera Active';
                    startBtn.disabled = true;
                    captureBtn.disabled = false;
                    
                    statusEl.textContent = 'Camera ready! Click "Analyze Image" to detect objects.';
                    statusEl.className = 'status success';
                };

            } catch (error) {
                console.error('Error accessing camera:', error);
                statusEl.textContent = 'Error accessing camera. Please check permissions.';
                statusEl.className = 'status error';
            }
        }

        async function captureAndAnalyze() {
            if (!isModelLoaded) {
                statusEl.textContent = 'Model not loaded yet. Please wait.';
                statusEl.className = 'status error';
                return;
            }

            try {
                statusEl.textContent = 'Analyzing image...';
                statusEl.className = 'status loading';
                captureBtn.disabled = true;

                // Draw video frame to canvas
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

                // Preprocess image for model
                const tensor = tf.browser.fromPixels(canvas)
                    .resizeNearestNeighbor([224, 224])
                    .expandDims(0)
                    .div(255.0);

                // Make prediction
                const predictions = await model.predict(tensor).data();
                
                // Get top 5 predictions
                const top5 = Array.from(predictions)
                    .map((p, i) => ({
                        className: window.imagenetClasses[i],
                        probability: p
                    }))
                    .sort((a, b) => b.probability - a.probability)
                    .slice(0, 5);

                // Display results
                displayResults(top5);

                // Clean up tensor
                tensor.dispose();

                statusEl.textContent = 'Analysis complete!';
                statusEl.className = 'status success';
                captureBtn.disabled = false;

            } catch (error) {
                console.error('Error during analysis:', error);
                statusEl.textContent = 'Error during analysis. Please try again.';
                statusEl.className = 'status error';
                captureBtn.disabled = false;
            }
        }

        function displayResults(predictions) {
            predictionsEl.innerHTML = '';
            
            predictions.forEach(prediction => {
                const confidence = Math.round(prediction.probability * 100);
                if (confidence > 5) { // Only show predictions with > 5% confidence
                    const resultItem = document.createElement('div');
                    resultItem.className = 'result-item';
                    resultItem.innerHTML = `
                        <span class="object-name">${prediction.className}</span>
                        <span class="confidence">${confidence}%</span>
                    `;
                    predictionsEl.appendChild(resultItem);
                }
            });

            resultsEl.style.display = 'block';
        }

        // Initialize the app when page loads
        window.addEventListener('load', init);
    </script>
</body>
</html>